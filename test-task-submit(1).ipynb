{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104174,"databundleVersionId":12533653,"sourceType":"competition"},{"sourceId":12039838,"sourceType":"datasetVersion","datasetId":7576171}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:12.915684Z","iopub.execute_input":"2025-06-04T01:13:12.915976Z","iopub.status.idle":"2025-06-04T01:13:12.925098Z","shell.execute_reply.started":"2025-06-04T01:13:12.915955Z","shell.execute_reply":"2025-06-04T01:13:12.923823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:15.805028Z","iopub.execute_input":"2025-06-04T01:13:15.805367Z","iopub.status.idle":"2025-06-04T01:13:19.600126Z","shell.execute_reply.started":"2025-06-04T01:13:15.805344Z","shell.execute_reply":"2025-06-04T01:13:19.599146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:21.794392Z","iopub.execute_input":"2025-06-04T01:13:21.794802Z","iopub.status.idle":"2025-06-04T01:13:21.799532Z","shell.execute_reply.started":"2025-06-04T01:13:21.794768Z","shell.execute_reply":"2025-06-04T01:13:21.798725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load Data\ntrain = pd.read_csv('/kaggle/input/test-task-for-ds-churn-prediction-2025-06/train.csv')\ntest = pd.read_csv('/kaggle/input/test-task-for-ds-churn-prediction-2025-06/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:25.03396Z","iopub.execute_input":"2025-06-04T01:13:25.034377Z","iopub.status.idle":"2025-06-04T01:13:25.199509Z","shell.execute_reply.started":"2025-06-04T01:13:25.034349Z","shell.execute_reply":"2025-06-04T01:13:25.198632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#EDA\nplt.figure(figsize=(6,4))\nsns.countplot(x='target_class', data=train)\nplt.title('Class Distribution')\nplt.xlabel('Churn (1) / Not Churned (0)')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:27.558036Z","iopub.execute_input":"2025-06-04T01:13:27.558701Z","iopub.status.idle":"2025-06-04T01:13:27.71325Z","shell.execute_reply.started":"2025-06-04T01:13:27.558672Z","shell.execute_reply":"2025-06-04T01:13:27.712447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Split data into two sets (training and validation)\nX = train.drop(columns=['Unnamed: 0', 'target_class'])\ny = train['target_class']\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:30.514863Z","iopub.execute_input":"2025-06-04T01:13:30.515653Z","iopub.status.idle":"2025-06-04T01:13:30.550931Z","shell.execute_reply.started":"2025-06-04T01:13:30.515618Z","shell.execute_reply":"2025-06-04T01:13:30.550065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train the XBBoost model\nxgb_model = xgb.XGBClassifier(\n    random_state=42,\n    n_estimators=100,        # fewer trees to avoid timeout\n    max_depth=7,             # slightly deeper\n    learning_rate=0.05,      # smaller learning rate\n    subsample=0.8,           # row dropout to avoid overfitting\n    colsample_bytree=0.8,    # feature dropout to avoid overfitting\n    scale_pos_weight=4.0,    # to handle class imbalance\n    eval_metric='logloss',\n    use_label_encoder=False\n)\n\nxgb_model.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:32.677238Z","iopub.execute_input":"2025-06-04T01:13:32.678071Z","iopub.status.idle":"2025-06-04T01:13:34.599184Z","shell.execute_reply.started":"2025-06-04T01:13:32.678043Z","shell.execute_reply":"2025-06-04T01:13:34.598659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Make predictions for the test data\ny_pred_val = xgb_model.predict(X_val)\nmcc_score = matthews_corrcoef(y_val, y_pred_val)\nprint(f\"Validation MCC: {mcc_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:40.71562Z","iopub.execute_input":"2025-06-04T01:13:40.715974Z","iopub.status.idle":"2025-06-04T01:13:40.739853Z","shell.execute_reply.started":"2025-06-04T01:13:40.715948Z","shell.execute_reply":"2025-06-04T01:13:40.738599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get feature importances as a dataframe\nimportances = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': xgb_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\n# Plot\nplt.figure(figsize=(10,8))\nsns.barplot(data=importances.head(20), x='Importance', y='Feature')\nplt.title('Top 20 Feature Importances (XGBoost)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:42.394871Z","iopub.execute_input":"2025-06-04T01:13:42.395175Z","iopub.status.idle":"2025-06-04T01:13:42.703522Z","shell.execute_reply.started":"2025-06-04T01:13:42.395145Z","shell.execute_reply":"2025-06-04T01:13:42.702617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Feature importance plot\nplt.figure(figsize=(10,6))\nxgb.plot_importance(xgb_model, max_num_features=15)\nplt.title('Top 15 Feature Importances (XGBoost)')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:47.634614Z","iopub.execute_input":"2025-06-04T01:13:47.634908Z","iopub.status.idle":"2025-06-04T01:13:47.894488Z","shell.execute_reply.started":"2025-06-04T01:13:47.634886Z","shell.execute_reply":"2025-06-04T01:13:47.893651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Generate test predictions\nX_test = test.drop(columns=['Unnamed: 0'])\ntest_preds = xgb_model.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:51.12724Z","iopub.execute_input":"2025-06-04T01:13:51.127593Z","iopub.status.idle":"2025-06-04T01:13:51.148225Z","shell.execute_reply.started":"2025-06-04T01:13:51.12755Z","shell.execute_reply":"2025-06-04T01:13:51.147546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Save the results\nsubmission = pd.DataFrame({\n    'id': test['Unnamed: 0'],\n    'target_class': test_preds\n})\nsubmission.to_csv('/content/churn_predictions.csv', index=False)\nprint(\"Done! Results saved to churn_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T01:13:52.718209Z","iopub.execute_input":"2025-06-04T01:13:52.71852Z","iopub.status.idle":"2025-06-04T01:13:52.732097Z","shell.execute_reply.started":"2025-06-04T01:13:52.718496Z","shell.execute_reply":"2025-06-04T01:13:52.731013Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this project, I tackled the problem of predicting customer churn using machine learning on tabular data. My goal was to identify customers who are likely to stop using a product or service within a given period.\n\nI started by performing exploratory data analysis (EDA) to understand the dataset’s structure, class imbalance, and feature characteristics.  Observed that the churn class was highly imbalanced (approximately 80% churned customers vs. 20% retained), which required careful modeling and evaluation strategies.\n\nn_estimators = 100\n\nmax_depth = 7\n\nlearning_rate = 0.05\n\nscale_pos_weight = 4.0 (to address class imbalance)\n\nsubsample = 0.8 and colsample_bytree = 0.8 (to reduce overfitting)\n\nClass Distribution Plot — uses seaborn’s countplot to show the imbalance in churned vs. non-churned customers.\n\nFeature Importance Plot — uses XGBoost’s built-in plot_importance to visualize the top features driving model predictions.\n\nI then used the trained XGBoost model to generate predictions on the test set. These predictions were saved in a submission file (churn_predictions.csv) containing the customer IDs and the predicted churn labels.\n\nOverall, the model I developed provides a solid baseline for churn prediction on this dataset. With further improvements such as hyperparameter tuning (e.g., Optuna) or advanced ensembling techniques, the model’s performance could potentially be enhanced even further.\n\nThis project demonstrates the effectiveness of techniques in predicting customer churn from structured tabular data, offering valuable insights for businesses to proactively retain customers and improve service quality.","metadata":{}}]}